<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>MergedBitmap.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">CIA</a> &gt; <a href="index.source.html" class="el_package">com.mbww.cia.dev.bitmap</a> &gt; <span class="el_source">MergedBitmap.scala</span></div><h1>MergedBitmap.scala</h1><pre class="source lang-java linenums">package com.mbww.cia.dev.bitmap

import com.mbww.cia.common.Spark._
import com.mbww.cia.common.bitmap.BitmapFileFormat
import com.mbww.cia.common.{Module, _}
import com.mbww.cia.core.exception.EmptyFilteredDataFrameException
import org.apache.spark.sql._
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._
import org.apache.spark.storage.StorageLevel
import org.json.JSONObject

import scala.collection._

<span class="fc" id="L15">class MergedBitmap extends Module {</span>

<span class="pc bpc" id="L17" title="43 of 44 branches missed.">  case class DenormalizedEntity(denormalizedPath: String, denormalizedId: String, denormalizedFilterExpr: String)</span>
<span class="pc bpc" id="L18" title="43 of 44 branches missed.">  case class InfobaseEntity(infobasePath: String, infobaseId: String, infobaseBitmapId: String)</span>
<span class="pc bpc" id="L19" title="43 of 44 branches missed.">  case class CrosswalkEntity(crosswalkPath: String, crosswalkId: String, crosswalkConsumerPel: String)</span>
<span class="pc bpc" id="L20" title="38 of 39 branches missed.">  case class ProcessingInfo(repartitionSize: Int, batchSize: Int, threadCount: Int, temporaryPath: String)</span>

  def generate(denormalizedEntity: DenormalizedEntity,
               infobaseEntity: InfobaseEntity,
               crosswalkEntity: CrosswalkEntity,
               attributeId: String,
               outputPath: String,
<span class="fc" id="L27">               processingInfo: ProcessingInfo): Unit = {</span>


<span class="fc bfc" id="L30" title="All 2 branches covered.">    val denormalized = if (!denormalizedEntity.denormalizedFilterExpr.isEmpty) {</span>
<span class="fc" id="L31">      val filteredDF = spark.read.parquet(denormalizedEntity.denormalizedPath).filter(denormalizedEntity.denormalizedFilterExpr)</span>
<span class="pc bpc" id="L32" title="1 of 2 branches missed.">      if (filteredDF.count() == 0) {</span>
<span class="fc" id="L33">        throw EmptyFilteredDataFrameException(</span>
<span class="fc" id="L34">          s&quot; The filter expression  ${denormalizedEntity.denormalizedFilterExpr} does not return any output on the path ${denormalizedEntity.denormalizedPath} &quot;)</span>
      }
<span class="nc" id="L36">      filteredDF.persist(StorageLevel.DISK_ONLY)</span>
    } else {
<span class="fc" id="L38">      spark.read.parquet(denormalizedEntity.denormalizedPath)</span>
    }

<span class="fc" id="L41">    val infobase = spark.read.parquet(infobaseEntity.infobasePath)</span>

<span class="pc bpc" id="L43" title="1 of 2 branches missed.">    val mappingKeys = if (!crosswalkEntity.crosswalkPath.isEmpty) {</span>
<span class="nc" id="L44">      val crosswalk = spark.read.parquet(crosswalkEntity.crosswalkPath)</span>
<span class="nc" id="L45">      crosswalk</span>
<span class="nc" id="L46">        .join(infobase, crosswalk(crosswalkEntity.crosswalkConsumerPel) === infobase(infobaseEntity.infobaseId))</span>
<span class="nc" id="L47">        .withColumn(Constants.MERGE_KEY, crosswalk(crosswalkEntity.crosswalkId))</span>
<span class="nc" id="L48">        .persist(StorageLevel.MEMORY_ONLY)</span>
    } else {
<span class="fc" id="L50">      infobase</span>
<span class="fc" id="L51">        .withColumn(Constants.MERGE_KEY, col(infobaseEntity.infobaseId))</span>
<span class="fc" id="L52">        .persist(StorageLevel.MEMORY_ONLY)</span>
    }

<span class="fc" id="L55">    val tmpPath = concatToPath(processingInfo.temporaryPath, s&quot;merged_bitmaps_${System.currentTimeMillis()}&quot;)</span>

<span class="pc bpc" id="L57" title="1 of 2 branches missed.">    if (processingInfo.repartitionSize.toInt == 1) {</span>
<span class="nc" id="L58">      val bitmapWriter = (df: DataFrame) =&gt; {</span>
<span class="nc" id="L59">        df.withColumn(BitmapFileFormat.IndexColumn, mappingKeys(infobaseEntity.infobaseBitmapId).cast(IntegerType))</span>
<span class="nc" id="L60">          .select(BitmapFileFormat.IndexColumn, attributeId).repartition(1)</span>
<span class="nc" id="L61">          .write</span>
<span class="nc" id="L62">          .mode(SaveMode.Append)</span>
<span class="nc" id="L63">          .format(classOf[BitmapFileFormat].getName)</span>
<span class="nc" id="L64">          .option(&quot;mapreduce.fileoutputcommitter.algorithm.version&quot;, &quot;2&quot;)</span>
<span class="nc" id="L65">          .option(&quot;mapreduce.fileoutputcommitter.marksuccessfuljobs&quot;, &quot;false&quot;)</span>
<span class="nc" id="L66">          .partitionBy(attributeId)</span>
<span class="nc" id="L67">          .save(tmpPath)</span>
      }

<span class="nc" id="L70">      val joinCondition = mappingKeys(Constants.MERGE_KEY) === denormalized(denormalizedEntity.denormalizedId)</span>
<span class="nc" id="L71">      val joinType = &quot;inner&quot;</span>

<span class="nc bnc" id="L73" title="All 2 branches missed.">      if (processingInfo.batchSize &lt;= 0) {</span>
<span class="nc" id="L74">        val df = denormalized.join(mappingKeys, joinCondition, joinType)</span>
<span class="nc" id="L75">        bitmapWriter(df)</span>
      } else {
<span class="nc" id="L77">        denormalized.batchJoin(mappingKeys, joinCondition, joinType, processingInfo.batchSize, Seq(denormalized(attributeId)), bitmapWriter)</span>
      }
<span class="nc" id="L79">      repartitionBitmaps(tmpPath, outputPath, attributeId, processingInfo.threadCount)</span>

    }

    else {
<span class="fc" id="L84">      val bitmapWriter = (df: DataFrame) =&gt; {</span>
<span class="fc" id="L85">        df.withColumn(BitmapFileFormat.IndexColumn, mappingKeys(infobaseEntity.infobaseBitmapId).cast(IntegerType))</span>
<span class="fc" id="L86">          .select(BitmapFileFormat.IndexColumn, attributeId)</span>
<span class="fc" id="L87">          .write</span>
<span class="fc" id="L88">          .mode(SaveMode.Append)</span>
<span class="fc" id="L89">          .format(classOf[BitmapFileFormat].getName)</span>
<span class="fc" id="L90">          .option(&quot;mapreduce.fileoutputcommitter.algorithm.version&quot;, &quot;2&quot;)</span>
<span class="fc" id="L91">          .option(&quot;mapreduce.fileoutputcommitter.marksuccessfuljobs&quot;, &quot;false&quot;)</span>
<span class="fc" id="L92">          .partitionBy(attributeId)</span>
<span class="fc" id="L93">          .save(tmpPath)</span>
      }

<span class="fc" id="L96">      val joinCondition = mappingKeys(Constants.MERGE_KEY) === denormalized(denormalizedEntity.denormalizedId)</span>
<span class="fc" id="L97">      val joinType = &quot;inner&quot;</span>

<span class="pc bpc" id="L99" title="1 of 2 branches missed.">      if (processingInfo.batchSize &lt;= 0) {</span>
<span class="fc" id="L100">        val df = denormalized.join(mappingKeys, joinCondition, joinType)</span>
<span class="fc" id="L101">        bitmapWriter(df)</span>
      } else {
<span class="nc" id="L103">        denormalized.batchJoin(mappingKeys, joinCondition, joinType, processingInfo.batchSize, Seq(denormalized(attributeId)), bitmapWriter)</span>
      }
<span class="fc" id="L105">      repartitionBitmaps(tmpPath, outputPath, attributeId, processingInfo.threadCount)</span>
    }
  }

  override def run(args: JSONObject): Unit = {

<span class="fc" id="L111">    val denormalizedPath = args.getString(&quot;denormalized_path&quot;)</span>
<span class="fc" id="L112">    val denormalizedId = args.getString(&quot;denormalized_id&quot;)</span>
<span class="fc" id="L113">    val denormalizedFilterExpr = args.getString(&quot;denormalized_filter_expr&quot;)</span>

<span class="fc" id="L115">    val denormalizedEntity = DenormalizedEntity(denormalizedPath,denormalizedId,denormalizedFilterExpr)</span>

<span class="fc" id="L117">    val infobasePath = args.getString(&quot;infobase_path&quot;)</span>
<span class="fc" id="L118">    val infobaseId = args.getString(&quot;infobase_id&quot;)</span>
<span class="fc" id="L119">    val infobaseBitmapId = args.getString(&quot;infobase_bitmap_id&quot;)</span>

<span class="fc" id="L121">    val infobaseEntity = InfobaseEntity(infobasePath,infobaseId,infobaseBitmapId)</span>

<span class="fc" id="L123">    val crosswalkPath = args.getString(&quot;crosswalk_path&quot;)</span>
<span class="fc" id="L124">    val crosswalkId = args.getString(&quot;crosswalk_id&quot;)</span>
<span class="fc" id="L125">    val crosswalkConsumerPel = args.getString(&quot;crosswalk_consumer_pel&quot;)</span>

<span class="fc" id="L127">    val crosswalkEntity = CrosswalkEntity(crosswalkPath, crosswalkId, crosswalkConsumerPel)</span>

<span class="fc" id="L129">    val partitionAttributeId = args.getString(&quot;partition_attribute_id&quot;)</span>

<span class="fc" id="L131">    val outputPath = args.getString(&quot;output_path&quot;)</span>

<span class="fc" id="L133">    val repartitionSize = args.getOrElse[Int](&quot;repartitionSize&quot;, 0)</span>
<span class="fc" id="L134">    val batchSize = args.getOrElse[Int](&quot;batch_size&quot;, 0)</span>
<span class="fc" id="L135">    val threadCount = args.getOrElse[Int](&quot;thread_count&quot;, 1)</span>
<span class="fc" id="L136">    val temporaryPath = args.getOrElse[String](&quot;temporary_path&quot;, &quot;/__CIA__tmp__/&quot;)</span>

<span class="fc" id="L138">    val processingInfo = ProcessingInfo(repartitionSize, batchSize, threadCount, temporaryPath)</span>

<span class="fc" id="L140">    generate(</span>
<span class="fc" id="L141">      denormalizedEntity,</span>
<span class="fc" id="L142">      infobaseEntity,</span>
<span class="fc" id="L143">      crosswalkEntity,</span>
<span class="fc" id="L144">      partitionAttributeId,</span>
<span class="fc" id="L145">      outputPath,</span>
<span class="fc" id="L146">      processingInfo)</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.1.201803210924</span></div></body></html>