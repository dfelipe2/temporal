<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>ConnectionsSurveyValidation.scala</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">CIA</a> &gt; <a href="index.source.html" class="el_package">com.mbww.cia.qa.denormalizer</a> &gt; <span class="el_source">ConnectionsSurveyValidation.scala</span></div><h1>ConnectionsSurveyValidation.scala</h1><pre class="source lang-java linenums">package com.mbww.cia.qa.denormalizer

import com.mbww.cia.common.Module
import com.mbww.cia.common.Spark.spark
import org.apache.spark.sql.functions.{col, concat, lit}
import org.json.JSONObject
import org.slf4j.LoggerFactory

<span class="fc" id="L9">class ConnectionsSurveyValidation  extends Module{</span>

<span class="fc" id="L11">  val logger = LoggerFactory.getLogger(&quot;CIA Pipeline&quot;)</span>

  def validateDenormData(ipgcx_uk_map_342278_parquet_inputpath: String, ipg_question_groups_parquet_inputpath: String, ipg_connections_mb_crossref_342278_parquet_inputpath: String, ipgcx_uk_respondent_342278_parquet_inputpath: String, ipgcx_uk_response_342278_parquet_inputpath: String,display_definition_data_outpath: String, connections_survey_denormalized_outpath: String,testType:String): Boolean =
  {
<span class="fc" id="L15">    val crossref_df = spark.read.parquet(ipg_connections_mb_crossref_342278_parquet_inputpath)</span>
<span class="fc" id="L16">    crossref_df.createOrReplaceTempView(&quot;crossref_df_view&quot;)</span>

<span class="fc" id="L18">    val map_df = spark.read.parquet(ipgcx_uk_map_342278_parquet_inputpath)</span>
<span class="fc" id="L19">    val map_sel_cols_df = map_df.select(&quot;variable_id&quot;, &quot;answer_code&quot;, &quot;question_label&quot;, &quot;answer_label&quot;)</span>
<span class="fc" id="L20">    val main_map_sel_cols_df = map_sel_cols_df.filter(&quot;answer_code is NOT NULL and answer_label is NOT NULL&quot;).dropDuplicates(&quot;variable_id&quot;, &quot;answer_code&quot;, &quot;question_label&quot;, &quot;answer_label&quot;)</span>

<span class="fc" id="L22">    val ipg_question_groups_df = spark.read.parquet(ipg_question_groups_parquet_inputpath)</span>
<span class="fc" id="L23">    val main_ipg_question_groups_df = ipg_question_groups_df.withColumn(&quot;variable_id1&quot;, concat(lit(&quot;DM&quot;), col(&quot;ITEM_CODE&quot;)))</span>
<span class="fc" id="L24">    val main_map_df = main_ipg_question_groups_df.join(main_map_sel_cols_df, main_map_sel_cols_df(&quot;variable_id&quot;) === main_ipg_question_groups_df(&quot;variable_id1&quot;), &quot;inner&quot;).withColumn(&quot;display_name&quot;, concat(main_ipg_question_groups_df(&quot;GROUP&quot;), lit(&quot; &gt;&gt; &quot;), main_ipg_question_groups_df(&quot;QUESTION&quot;), lit(&quot; &gt;&gt; &quot;), main_map_sel_cols_df(&quot;answer_label&quot;))).drop(&quot;question_label&quot;, &quot;answer_label&quot;, &quot;GROUP&quot;, &quot;variable_id1&quot;, &quot;ITEM_CODE&quot;, &quot;QUESTION&quot;)</span>
<span class="fc" id="L25">    main_map_df.createOrReplaceTempView(&quot;main_map_df_view&quot;)</span>

    /** Creating display_name definition list*/
<span class="pc bpc" id="L28" title="1 of 2 branches missed.">    val df_disp_def = if (!display_definition_data_outpath.isEmpty) {</span>
<span class="fc" id="L29">      val display_df = main_map_df.withColumn(&quot;attributeid&quot;, concat(col(&quot;variable_id&quot;), col(&quot;answer_code&quot;))).select(&quot;attributeid&quot;, &quot;display_name&quot;)</span>
<span class="fc" id="L30">      val main_display_df = display_df.dropDuplicates(&quot;attributeid&quot;, &quot;display_name&quot;)</span>
<span class="fc" id="L31">    }</span>

<span class="fc" id="L33">    val respondent_df = spark.read.parquet(ipgcx_uk_respondent_342278_parquet_inputpath)</span>
<span class="fc" id="L34">    val respondent_sel_cols_df = respondent_df.select(&quot;customer_id&quot;, &quot;pdate&quot;, &quot;puuid&quot;)</span>
<span class="fc" id="L35">    val main_respondent_sel_cols_df = respondent_sel_cols_df.drop(&quot;puuid&quot;).filter(&quot;customer_id is NOT NULL and pdate is NOT NULL and pdate != ''&quot;).dropDuplicates(&quot;customer_id&quot;, &quot;pdate&quot;)</span>
<span class="fc" id="L36">    main_respondent_sel_cols_df.createOrReplaceTempView(&quot;main_respondent_sel_cols_df_view&quot;)</span>

<span class="fc" id="L38">    val response_df = spark.read.parquet(ipgcx_uk_response_342278_parquet_inputpath)</span>
<span class="fc" id="L39">    val filterresponse_df=response_df.select(&quot;variable_id&quot;,&quot;response&quot;)</span>
<span class="pc bpc" id="L40" title="1 of 2 branches missed.">    if(!testType.isEmpty)</span>
    {
<span class="fc" id="L42">      filterresponse_df.createOrReplaceTempView(&quot;filterresponse_df_view&quot;)</span>
    }
    else
    {
<span class="nc" id="L46">      var filterresponse_df1=filterresponse_df.sample(true,.000007,1L)</span>
<span class="nc" id="L47">      filterresponse_df1.createOrReplaceTempView(&quot;filterresponse_df_view&quot;)</span>
    }

<span class="fc" id="L50">    val sampleData=spark.sql(&quot;select variable_id,response,concat(variable_id,response) as attributeid from filterresponse_df_view&quot;)</span>
<span class="fc" id="L51">    val attributeIds=sampleData.select(&quot;attributeid&quot;)</span>
<span class="fc" id="L52">    var pValues = attributeIds.collect()</span>

<span class="fc" id="L54">    val main_response_sel_cols_df = response_df.filter(&quot;response is NOT NULL&quot;).join(main_ipg_question_groups_df, response_df(&quot;variable_id&quot;) === main_ipg_question_groups_df(&quot;variable_id1&quot;), &quot;inner&quot;).drop(&quot;ITEM_CODE&quot;, &quot;GROUP&quot;, &quot;QUESTION&quot;, &quot;variable_id1&quot;)</span>
<span class="fc" id="L55">    main_response_sel_cols_df.createOrReplaceTempView(&quot;main_response_sel_cols_df_view&quot;)</span>

    // FILTERED MAIN QUERY - DATAFRAME

<span class="fc" id="L59">    main_map_df.createOrReplaceTempView(&quot;main_map_df_view&quot;)</span>

<span class="fc" id="L61">    val fil_main_query_df = spark.sql(&quot;select fuse.customer_id, fuse.mbid_v2, concat(resp.variable_id, resp.response) as attributeid &quot; +</span>
      &quot;from crossref_df_view fuse &quot; +
      &quot;inner join main_respondent_sel_cols_df_view rspdt ON fuse.customer_id = rspdt.customer_id &quot; +
<span class="fc" id="L64">      &quot;inner join main_response_sel_cols_df_view resp ON rspdt.customer_id = resp.customer_id  and rspdt.pdate = resp.pdate &quot; +</span>
      &quot;inner join main_map_df_view map1 on (upper(resp.variable_id) = upper(map1.variable_id) AND resp.response = map1.answer_code) &quot;)

<span class="fc" id="L67">    fil_main_query_df.createOrReplaceTempView(&quot;fil_main_query_df_view&quot;)</span>
<span class="fc" id="L68">    val denorm_df = spark.sql(&quot;Select mbid_v2, attributeid from (select customer_id, mbid_v2, attributeid, ROW_NUMBER() OVER(PARTITION BY customer_id, attributeid ORDER BY attributeid) as RowNum from fil_main_query_df_view)x where RowNum=1&quot;)</span>
<span class="fc" id="L69">    val actualDenormData=spark.read.load(connections_survey_denormalized_outpath)</span>
<span class="pc bpc" id="L70" title="1 of 2 branches missed.">    pValues.foreach { x =&gt;</span>
<span class="fc" id="L71">      val att=x.mkString</span>
<span class="fc" id="L72">      val expectedData=denorm_df.filter(s&quot;attributeid='${att}'&quot;)</span>
<span class="fc" id="L73">      val actualData=actualDenormData.filter(s&quot;attributeid='${att}'&quot;)</span>
<span class="fc" id="L74">      val expectedCount=expectedData.count()</span>
<span class="fc" id="L75">      val actualcount=actualData.count()</span>
<span class="pc bpc" id="L76" title="1 of 2 branches missed.">      if(!(actualcount ==expectedCount)) {</span>
<span class="nc" id="L77">        throw new RuntimeException(</span>
<span class="nc" id="L78">          s&quot;Actual file count ${actualcount} is not same as Expected count ${expectedCount} proscess data for the attribute Id ${att}&quot;)</span>
      }
<span class="fc" id="L80">      logger.info(   s&quot;Actual file count ${actualcount} is  same as Expected count ${expectedCount} proscess data for the attribute Id ${att}&quot;)</span>

    }
<span class="fc" id="L83">    true</span>
  }

  override def run(args: JSONObject): Unit = {

<span class="fc" id="L88">    val ipgcx_uk_map_342278_parquet_inputpath = args.getString(&quot;ipgcx_uk_map_342278_parquet_inputpath&quot;)</span>
<span class="fc" id="L89">    val ipg_question_groups_parquet_inputpath = args.getString(&quot;ipg_question_groups_parquet_inputpath&quot;)</span>
<span class="fc" id="L90">    val ipg_connections_mb_crossref_342278_parquet_inputpath = args.getString(&quot;ipg_connections_mb_crossref_342278_parquet_inputpath&quot;)</span>
<span class="fc" id="L91">    val ipgcx_uk_respondent_342278_parquet_inputpath = args.getString(&quot;ipgcx_uk_respondent_342278_parquet_inputpath&quot;)</span>
<span class="fc" id="L92">    val ipgcx_uk_response_342278_parquet_inputpath = args.getString(&quot;ipgcx_uk_response_342278_parquet_inputpath&quot;)</span>
<span class="fc" id="L93">    val display_definition_data_outpath = args.getString(&quot;display_definition_data_outpath&quot;)</span>
<span class="fc" id="L94">    val connections_survey_denormalized_outpath = args.getString(&quot;connections_survey_denormalized_outpath&quot;)</span>
<span class="fc" id="L95">    val testType=args.getString(&quot;testType&quot;)</span>

<span class="fc" id="L97">    validateDenormData(</span>
<span class="fc" id="L98">      ipgcx_uk_map_342278_parquet_inputpath,</span>
<span class="fc" id="L99">      ipg_question_groups_parquet_inputpath,</span>
<span class="fc" id="L100">      ipg_connections_mb_crossref_342278_parquet_inputpath,</span>
<span class="fc" id="L101">      ipgcx_uk_respondent_342278_parquet_inputpath,</span>
<span class="fc" id="L102">      ipgcx_uk_response_342278_parquet_inputpath,</span>
<span class="fc" id="L103">      display_definition_data_outpath,</span>
<span class="fc" id="L104">      connections_survey_denormalized_outpath,</span>
<span class="fc" id="L105">      testType</span>
    )
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.1.201803210924</span></div></body></html>